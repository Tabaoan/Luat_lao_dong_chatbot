# ===================== IMPORTS =====================
import os, re, io
from typing import Dict, Any, List
from pathlib import Path

from chromadb.config import Settings
from dotenv import load_dotenv
load_dotenv(override=True)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage
from langchain_community.document_loaders import PyMuPDFLoader

# ===================== ENV =====================
OPENAI__API_KEY = os.getenv("OPENAI__API_KEY")
OPENAI__EMBEDDING_MODEL = os.getenv("OPENAI__EMBEDDING_MODEL")
OPENAI__MODEL_NAME = os.getenv("OPENAI__MODEL_NAME")
OPENAI__TEMPERATURE = os.getenv("OPENAI__TEMPERATURE")

llm = ChatOpenAI(
    api_key=OPENAI__API_KEY,
    model_name=OPENAI__MODEL_NAME,
    temperature=float(OPENAI__TEMPERATURE) if OPENAI__TEMPERATURE else 0
)

# ===================== VECTORDB =====================
VECTORDB_PATH = r"./vectordb_storage"
os.makedirs(VECTORDB_PATH, exist_ok=True)

emb = OpenAIEmbeddings(api_key=OPENAI__API_KEY, model=OPENAI__EMBEDDING_MODEL)

vectordb = None
retriever = None

# ===================== PDF FOLDER =====================
PDF_FOLDER = r"C:\Users\tabao\Downloads\Luat_lao_dong_chatbot\data"

def get_pdf_files_from_folder(folder_path: str) -> List[str]:
    """Láº¥y táº¥t cáº£ file PDF trong folder"""
    pdf_files = []
    if not os.path.exists(folder_path):
        print(f"âš ï¸ Folder khÃ´ng tá»“n táº¡i: {folder_path}")
        return pdf_files
    
    for file in os.listdir(folder_path):
        if file.lower().endswith('.pdf'):
            full_path = os.path.join(folder_path, file)
            pdf_files.append(full_path)
    
    return sorted(pdf_files)  # Sort Ä‘á»ƒ cÃ³ thá»© tá»± nháº¥t quÃ¡n

PDF_PATHS = get_pdf_files_from_folder(PDF_FOLDER)

# ===================== SYSTEM PROMPT =====================
PDF_READER_SYS = (
    "Báº¡n lÃ  má»™t **trá»£ lÃ½ AI phÃ¡p lÃ½** chuyÃªn Ä‘á»c hiá»ƒu vÃ  tra cá»©u cÃ¡c tÃ i liá»‡u PDF Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p "
    "(bao gá»“m: Luáº­t, Nghá»‹ Ä‘á»‹nh, Quyáº¿t Ä‘á»‹nh, ThÃ´ng tÆ°, VÄƒn báº£n há»£p nháº¥t, v.v.). "
    "Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  **chá»‰ tráº£ lá»i cÃ¡c cÃ¢u há»i cÃ³ ná»™i dung liÃªn quan trá»±c tiáº¿p** Ä‘áº¿n phÃ¡p luáº­t Viá»‡t Nam, "
    "Ä‘áº·c biá»‡t lÃ  lÄ©nh vá»±c **Lao Ä‘á»™ng** vÃ  **DÃ¢n sá»±**.\n\n"
    
    "âš™ï¸ **QUY Táº®C Äáº¶C BIá»†T:**\n"
    "- Náº¿u ngÆ°á»i dÃ¹ng chá»‰ chÃ o há»i hoáº·c Ä‘áº·t cÃ¢u há»i chung chung (vÃ­ dá»¥: 'xin chÃ o', 'báº¡n lÃ m Ä‘Æ°á»£c gÃ¬', 'giÃºp tÃ´i vá»›i', ...), "
    "hÃ£y tráº£ lá»i **nguyÃªn vÄƒn** nhÆ° sau:\n"
    "'Xin chÃ o! MÃ¬nh lÃ  Chatbot Cá»•ng viá»‡c lÃ m Viá»‡t Nam. MÃ¬nh cÃ³ thá»ƒ giÃºp anh/chá»‹ tra cá»©u vÃ  giáº£i thÃ­ch cÃ¡c quy Ä‘á»‹nh phÃ¡p luáº­t "
    "(luáº­t, nghá»‹ Ä‘á»‹nh, thÃ´ng tÆ°...) liÃªn quan Ä‘áº¿n lao Ä‘á»™ng, viá»‡c lÃ m, dÃ¢n sá»± vÃ  cÃ¡c lÄ©nh vá»±c phÃ¡p lÃ½ khÃ¡c. "
    "GÃµ cÃ¢u há»i cá»¥ thá»ƒ hoáº·c mÃ´ táº£ tÃ¬nh huá»‘ng nhÃ© â€” mÃ¬nh sáº½ tráº£ lá»i ngáº¯n gá»n, cÃ³ dáº«n nguá»“n.'\n\n"
    
    "ğŸ“˜ **NGUYÃŠN Táº®C TRáº¢ Lá»œI:**\n"
    "1) **Pháº¡m vi:** Chá»‰ dá»±a vÃ o ná»™i dung trong cÃ¡c tÃ i liá»‡u PDF Ä‘Ã£ Ä‘Æ°á»£c cung cáº¥p; khÃ´ng sá»­ dá»¥ng hoáº·c suy diá»…n kiáº¿n thá»©c bÃªn ngoÃ i.\n"
    "2) **Nguá»“n trÃ­ch dáº«n:** Khi tráº£ lá»i, nÃªn dáº«n nguá»“n cá»¥ thá»ƒ (vÃ­ dá»¥: 'Theo Äiá»u X, Nghá»‹ Ä‘á»‹nh sá»‘ Y/NÄ-CP...').\n"
    "3) **NgÃ´n ngá»¯:** Viáº¿t theo phong cÃ¡ch phÃ¡p lÃ½, rÃµ rÃ ng, trung láº­p vÃ  tÃ´n trá»ng vÄƒn phong hÃ nh chÃ­nh.\n"
    "4) **TrÃ¬nh bÃ y:** Æ¯u tiÃªn liá»‡t kÃª báº±ng gáº¡ch Ä‘áº§u dÃ²ng (-) hoáº·c sá»‘ thá»© tá»± (1., 2., 3...) Ä‘á»ƒ ngÆ°á»i Ä‘á»c dá»… theo dÃµi.\n"
    "5) **Náº¿u thÃ´ng tin khÃ´ng cÃ³:** Tráº£ lá»i rÃµ rÃ ng: 'ThÃ´ng tin nÃ y khÃ´ng cÃ³ trong tÃ i liá»‡u Ä‘Æ°á»£c cung cáº¥p.'\n"
    "6) **Náº¿u cÃ¢u há»i mÆ¡ há»“:** YÃªu cáº§u ngÆ°á»i dÃ¹ng lÃ m rÃµ hoáº·c bá»• sung chi tiáº¿t Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c.\n\n"
    
    "ğŸ§© **VÃ Dá»¤ TRáº¢ Lá»œI:**\n"
    "Theo quy Ä‘á»‹nh táº¡i *Äiá»u X* cá»§a *Bá»™ luáº­t Lao Ä‘á»™ng 2019* hoáº·c *Bá»™ luáº­t DÃ¢n sá»± 2015*:\n"
    "- (1) TrÃ­ch dáº«n hoáº·c tÃ³m táº¯t ná»™i dung chÃ­nh cá»§a Ä‘iá»u luáº­t.\n"
    "- (2) Diá»…n giáº£i Ã½ nghÄ©a hoáº·c pháº¡m vi Ã¡p dá»¥ng.\n"
    "- (3) Náº¿u cÃ³ thá»ƒ, hÆ°á»›ng dáº«n cÃ¡ch Ã¡p dá»¥ng trong thá»±c táº¿.\n"
)


# ===================== VECTORDB UTILS =====================
def build_context_from_hits(hits, max_chars: int = 6000) -> str:
    """XÃ¢y dá»±ng context tá»« káº¿t quáº£ tÃ¬m kiáº¿m"""
    ctx = []
    total = 0
    for idx, h in enumerate(hits, start=1):
        source = h.metadata.get('source', 'unknown')
        seg = f"[{idx}] (Nguá»“n: {source})\n{h.page_content.strip()}"
        if total + len(seg) > max_chars:
            break
        ctx.append(seg)
        total += len(seg)
    return "\n\n".join(ctx)

def get_existing_sources() -> set:
    """Láº¥y danh sÃ¡ch file Ä‘Ã£ cÃ³ trong VectorDB"""
    global vectordb
    
    if vectordb is None:
        return set()
    
    try:
        collection = vectordb._collection
        existing_data = collection.get()
        
        if existing_data and existing_data.get('metadatas'):
            return set(m.get('source', '') for m in existing_data['metadatas'] if m and m.get('source'))
        
        return set()
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi láº¥y danh sÃ¡ch file: {e}")
        return set()

def check_vectordb_exists() -> bool:
    """Kiá»ƒm tra xem VectorDB cÃ³ Ä‘á»§ táº¥t cáº£ file PDF khÃ´ng"""
    global vectordb
    
    if vectordb is None:
        return False
    
    try:
        collection = vectordb._collection
        count = collection.count()
        
        if count == 0:
            return False
        
        # Kiá»ƒm tra xem Ä‘Ã£ cÃ³ Ä‘á»§ táº¥t cáº£ file PDF chÆ°a
        target_files = set(os.path.basename(p) for p in PDF_PATHS)
        existing_sources = get_existing_sources()
        
        return target_files.issubset(existing_sources)
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi kiá»ƒm tra VectorDB: {e}")
        return False

def get_vectordb_stats() -> Dict[str, Any]:
    """Láº¥y thÃ´ng tin thá»‘ng kÃª vá» VectorDB"""
    global vectordb
    
    if vectordb is None:
        return {"total_documents": 0, "path": VECTORDB_PATH, "exists": False}
    
    try:
        collection = vectordb._collection
        count = collection.count()
        
        # Láº¥y danh sÃ¡ch file Ä‘Ã£ náº¡p
        sources = get_existing_sources()
        
        return {
            "total_documents": count,
            "path": VECTORDB_PATH,
            "exists": count > 0,
            "sources": list(sources)
        }
    except Exception as e:
        return {
            "total_documents": 0,
            "path": VECTORDB_PATH,
            "exists": False,
            "error": str(e)
        }

# ===================== INGEST MULTIPLE PDFs (INCREMENTAL) =====================
def ingest_pdf(pdf_paths=None, vectordb_path=None, emb_fn=None, force_reload=False):
    """
    Náº¡p tÃ i liá»‡u PDF vÃ o VectorDB (incremental update)
    
    Args:
        pdf_paths: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n file PDF
        vectordb_path: ÄÆ°á»ng dáº«n lÆ°u VectorDB
        emb_fn: HÃ m embedding
        force_reload: Náº¿u True, xÃ³a VectorDB cÅ© vÃ  náº¡p láº¡i toÃ n bá»™
    """
    global vectordb, retriever

    pdf_paths = pdf_paths if pdf_paths is not None else PDF_PATHS
    vectordb_path = vectordb_path if vectordb_path is not None else VECTORDB_PATH
    emb_fn = emb_fn if emb_fn is not None else emb

    print("ğŸš€ Báº¯t Ä‘áº§u kiá»ƒm tra vÃ  náº¡p tÃ i liá»‡u PDF...\n")

    # Náº¿u force reload, xÃ³a toÃ n bá»™ vÃ  náº¡p láº¡i
    if force_reload:
        print("ğŸ—‘ï¸ Cháº¿ Ä‘á»™ force reload - XÃ³a toÃ n bá»™ VectorDB...")
        try:
            temp_db = Chroma(
                collection_name="luat_tong_hop_v1",
                embedding_function=emb_fn,
                persist_directory=vectordb_path,
            )
            temp_db.delete_collection()
            print("âœ… ÄÃ£ xÃ³a VectorDB cÅ©\n")
            vectordb = None
        except Exception as e:
            print(f"â„¹ï¸ KhÃ´ng cÃ³ VectorDB cÅ© Ä‘á»ƒ xÃ³a: {e}\n")

    # Khá»Ÿi táº¡o hoáº·c load VectorDB
    if vectordb is None:
        try:
            vectordb = Chroma(
                collection_name="luat_tong_hop_v1",
                embedding_function=emb_fn,
                persist_directory=vectordb_path,
            )
            print("ğŸ“‚ ÄÃ£ khá»Ÿi táº¡o/load VectorDB")
        except Exception as e:
            print(f"âŒ Lá»—i khá»Ÿi táº¡o VectorDB: {e}")
            return None

    # Láº¥y danh sÃ¡ch file Ä‘Ã£ cÃ³ trong VectorDB
    existing_sources = get_existing_sources()
    print(f"ğŸ“Š VectorDB hiá»‡n cÃ³: {len(existing_sources)} file")
    if existing_sources:
        print(f"   â””â”€ {', '.join(sorted(existing_sources))}")
    
    # XÃ¡c Ä‘á»‹nh file cáº§n náº¡p má»›i
    target_files = {os.path.basename(p): p for p in pdf_paths}
    new_files = {name: path for name, path in target_files.items() if name not in existing_sources}
    
    if not new_files:
        print(f"\nâœ… Táº¥t cáº£ {len(target_files)} file Ä‘Ã£ cÃ³ trong VectorDB!")
        print("ğŸ’¡ DÃ¹ng lá»‡nh 'reload' Ä‘á»ƒ náº¡p láº¡i toÃ n bá»™ náº¿u cáº§n.\n")
        retriever = vectordb.as_retriever(search_kwargs={"k": 10})
        return vectordb
    
    print(f"\nğŸ“¥ Cáº§n náº¡p {len(new_files)} file má»›i:")
    for name in sorted(new_files.keys()):
        print(f"   + {name}")
    print()

    all_new_docs = []
    total_chunks = 0

    # Äá»c vÃ  chunk tá»«ng file PDF má»›i
    for filename, path in new_files.items():
        if not os.path.exists(path):
            print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y file: {path}")
            continue

        print(f"ğŸ“– Äang Ä‘á»c: {filename} ...")

        loader = PyMuPDFLoader(path)
        try:
            docs = loader.load()
        except Exception as e:
            print(f"âŒ Lá»—i khi load {filename}: {e}")
            continue

        # Gáº¯n thÃ´ng tin nguá»“n file
        for i, d in enumerate(docs):
            if d.metadata is None:
                d.metadata = {}
            d.metadata["source"] = filename
            d.metadata["page"] = i + 1

        # Chunk ná»™i dung
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        split_docs = splitter.split_documents(docs)

        # Gáº¯n thÃªm chunk index
        for i, d in enumerate(split_docs):
            d.metadata["chunk_id"] = i

        print(f"   ğŸ”¹ Táº¡o {len(split_docs)} Ä‘oáº¡n tá»« {filename}")
        all_new_docs.extend(split_docs)
        total_chunks += len(split_docs)

    if not all_new_docs:
        print("âš ï¸ KhÃ´ng cÃ³ document má»›i nÃ o Ä‘á»ƒ náº¡p.")
        retriever = vectordb.as_retriever(search_kwargs={"k": 10})
        return vectordb

    print(f"\nğŸ“š Tá»•ng cá»™ng: {total_chunks} Ä‘oáº¡n ná»™i dung má»›i\n")

    # ThÃªm vÃ o VectorDB vá»›i ID duy nháº¥t
    print("ğŸ’¾ Äang thÃªm vÃ o VectorDB...")
    ids = []
    for d in all_new_docs:
        src = d.metadata.get("source", "unknown")
        page = d.metadata.get("page", 0)
        chunk = d.metadata.get("chunk_id", 0)
        ids.append(f"{src}_page{page}_chunk{chunk}")

    try:
        # Chia nhá» Ä‘á»ƒ trÃ¡nh lá»—i khi batch quÃ¡ lá»›n
        batch_size = 100
        for i in range(0, len(all_new_docs), batch_size):
            batch_docs = all_new_docs[i:i+batch_size]
            batch_ids = ids[i:i+batch_size]
            vectordb.add_documents(batch_docs, ids=batch_ids)
            print(f"   âœ“ ÄÃ£ thÃªm {min(i+batch_size, len(all_new_docs))}/{len(all_new_docs)} documents")
        
        print("âœ… ÄÃ£ thÃªm toÃ n bá»™ documents má»›i vÃ o VectorDB!")
    except Exception as e:
        print(f"âŒ Lá»—i khi thÃªm documents: {e}")
        return None

    # Cáº­p nháº­t retriever
    retriever = vectordb.as_retriever(search_kwargs={"k": 10})

    # Thá»‘ng kÃª cuá»‘i cÃ¹ng
    try:
        count = vectordb._collection.count()
        final_sources = get_existing_sources()
        print(f"\nğŸ“‚ LÆ°u táº¡i: {vectordb_path}")
        print(f"ğŸ“Š VectorDB hiá»‡n cÃ³:")
        print(f"   â€¢ Tá»•ng documents: {count}")
        print(f"   â€¢ Tá»•ng file: {len(final_sources)}")
        print(f"   â€¢ Danh sÃ¡ch: {', '.join(sorted(final_sources))}\n")
    except Exception as e:
        print(f"âš ï¸ KhÃ´ng thá»ƒ láº¥y thá»‘ng kÃª: {e}\n")

    return vectordb

# ===================== CLEANING & RETRIEVAL =====================
_URL_RE = re.compile(r"https?://[^\s]+", re.IGNORECASE)

def clean_question_remove_uris(text: str) -> str:
    """LÃ m sáº¡ch cÃ¢u há»i, loáº¡i bá» URL vÃ  tÃªn file PDF"""
    txt = _URL_RE.sub(" ", text or "")
    toks = re.split(r"\s+", txt)
    toks = [t for t in toks if not t.lower().endswith(".pdf")]
    return " ".join(toks).strip()

def process_pdf_question(i: Dict[str, Any]) -> str:
    """Xá»­ lÃ½ cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng"""
    global retriever
    
    message = i["message"]
    history: List[BaseMessage] = i.get("history", [])

    # Kiá»ƒm tra VectorDB
    if not check_vectordb_exists():
        print("âš ï¸ VectorDB chÆ°a sáºµn sÃ ng, Ä‘ang náº¡p PDF vÃ o há»‡ thá»‘ng...")
        result = ingest_pdf()
        if result is None:
            return "Xin lá»—i, tÃ´i gáº·p lá»—i khi náº¡p tÃ i liá»‡u PDF. Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n file."

    clean_question = clean_question_remove_uris(message)
    
    try:
        # TÃ¬m kiáº¿m trong VectorDB
        hits = retriever.invoke(clean_question)
        
        if not hits:
            return "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan trong tÃ i liá»‡u PDF."

        # XÃ¢y dá»±ng context tá»« káº¿t quáº£ tÃ¬m kiáº¿m
        context = build_context_from_hits(hits, max_chars=6000)
        
        # Táº¡o messages
        messages = [SystemMessage(content=PDF_READER_SYS)]

        if history:
            messages.extend(history[-10:])  # Chá»‰ láº¥y 10 tin nháº¯n gáº§n nháº¥t

        user_message = f"""CÃ¢u há»i: {clean_question}

Ná»™i dung liÃªn quan tá»« tÃ i liá»‡u PDF:
{context}

HÃ£y tráº£ lá»i dá»±a trÃªn cÃ¡c ná»™i dung trÃªn."""
        
        messages.append(HumanMessage(content=user_message))
        
        # Gá»i LLM
        response = llm.invoke(messages).content
        return response

    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return f"Xin lá»—i, tÃ´i gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}"

# ===================== MAIN CHATBOT =====================
pdf_chain = RunnableLambda(process_pdf_question)
store: Dict[str, ChatMessageHistory] = {}

def get_history(session_id: str):
    """Láº¥y hoáº·c táº¡o lá»‹ch sá»­ chat cho session"""
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

chatbot = RunnableWithMessageHistory(
    pdf_chain,
    get_history,
    input_messages_key="message",
    history_messages_key="history"
)

def print_help():
    """In hÆ°á»›ng dáº«n sá»­ dá»¥ng"""
    print("\n" + "="*60)
    print("ğŸ“š CÃC Lá»†NH CÃ“ Sáº´N:")
    print("="*60)
    print(" - exit / quit  : ThoÃ¡t chÆ°Æ¡ng trÃ¬nh")
    print(" - clear        : XÃ³a lá»‹ch sá»­ há»™i thoáº¡i")
    print(" - sync         : Äá»“ng bá»™ file má»›i tá»« folder vÃ o VectorDB")
    print(" - reload       : XÃ³a toÃ n bá»™ vÃ  náº¡p láº¡i (force reload)")
    print(" - status       : Kiá»ƒm tra tráº¡ng thÃ¡i VectorDB")
    print(" - help         : Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n nÃ y")
    print("="*60 + "\n")

def handle_command(command: str, session: str) -> bool:
    """Xá»­ lÃ½ cÃ¡c lá»‡nh Ä‘áº·c biá»‡t"""
    global vectordb, retriever
    cmd = command.lower().strip()

    if cmd in {"exit", "quit"}:
        print("\nğŸ‘‹ Táº¡m biá»‡t! Háº¹n gáº·p láº¡i!")
        return False
    
    elif cmd == "clear":
        if session in store:
            store[session].clear()
            print("ğŸ§¹ ÄÃ£ xÃ³a lá»‹ch sá»­ há»™i thoáº¡i.\n")
        return True
    
    elif cmd == "reload":
        print("ğŸ”„ Äang xÃ³a vÃ  náº¡p láº¡i toÃ n bá»™ PDF...")
        ingest_pdf(force_reload=True)
        return True
    
    elif cmd == "status":
        stats = get_vectordb_stats()
        print("\n" + "="*60)
        print("ğŸ“Š TRáº NG THÃI VECTORDB")
        print("="*60)
        if stats["exists"]:
            print(f"âœ… Tráº¡ng thÃ¡i: Sáºµn sÃ ng")
            print(f"ğŸ“Š Tá»•ng documents: {stats['total_documents']}")
            print(f"ğŸ“‚ ÄÆ°á»ng dáº«n: {stats['path']}")
            print(f"ğŸ“˜ CÃ¡c file Ä‘Ã£ náº¡p:")
            for src in stats.get('sources', []):
                print(f"   - {src}")
        else:
            print("âŒ Tráº¡ng thÃ¡i: ChÆ°a sáºµn sÃ ng")
            print("ğŸ’¡ HÃ£y Ä‘á»£i há»‡ thá»‘ng náº¡p PDF hoáº·c gÃµ 'reload'")
        print("="*60 + "\n")
        return True
    
    elif cmd == "help":
        print_help()
        return True
    
    else:
        return True

# ===================== CLI =====================
if __name__ == "__main__":
    session = "pdf_reader_session"

    print("\n" + "="*60)
    print("ğŸ¤– CHATBOT Cá»”NG VIá»†C LÃ€M VIá»†T NAM")
    print("="*60)
    print(f"ğŸ“ Folder tÃ i liá»‡u: {PDF_FOLDER}")
    print(f"ğŸ“š TÃ¬m tháº¥y {len(PDF_PATHS)} file PDF:")
    
    if PDF_PATHS:
        for idx, p in enumerate(PDF_PATHS, 1):
            status = "âœ…" if os.path.exists(p) else "âŒ"
            print(f"   {idx}. {status} {os.path.basename(p)}")
    else:
        print("   âš ï¸ KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong folder!")
    
    print(f"\nğŸ“‚ VectorDB: {VECTORDB_PATH}")
    print("ğŸ” TÃ´i há»— trá»£: Luáº­t Lao Ä‘á»™ng & Luáº­t DÃ¢n sá»± Viá»‡t Nam")
    print_help()

    # Khá»Ÿi táº¡o VectorDB
    if not PDF_PATHS:
        print("âŒ KhÃ´ng cÃ³ file PDF nÃ o Ä‘á»ƒ xá»­ lÃ½. Vui lÃ²ng kiá»ƒm tra láº¡i folder.")
        exit(1)
    
    if check_vectordb_exists():
        stats = get_vectordb_stats()
        print(f"âœ… VectorDB sáºµn sÃ ng vá»›i {stats['total_documents']} documents")
        print(f"ğŸ“š ÄÃ£ náº¡p: {', '.join(stats.get('sources', []))}\n")
    else:
        print("ğŸ“¥ Äang náº¡p PDF láº§n Ä‘áº§u tiÃªn...")
        result = ingest_pdf()
        if result is None:
            print("âŒ KhÃ´ng thá»ƒ khá»Ÿi táº¡o VectorDB. Vui lÃ²ng kiá»ƒm tra láº¡i Ä‘Æ°á»ng dáº«n file PDF.")
            exit(1)

    print("ğŸ’¬ Sáºµn sÃ ng tráº£ lá»i cÃ¢u há»i! (GÃµ 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n)\n")

    # Main loop
    while True:
        try:
            message = input("ğŸ‘¤ Báº¡n: ").strip()
            
            if not message:
                continue
            
            # Xá»­ lÃ½ lá»‡nh
            if not handle_command(message, session):
                break
            
            # Bá» qua náº¿u lÃ  lá»‡nh
            if message.lower() in ["clear", "reload", "status", "help"]:
                continue
            
            # Xá»­ lÃ½ cÃ¢u há»i thÆ°á»ng
            print("ğŸ” Äang tÃ¬m kiáº¿m trong tÃ i liá»‡u...")
            response = chatbot.invoke(
                {"message": message},
                config={"configurable": {"session_id": session}}
            )
            print(f"\nğŸ¤– Bot: {response}\n")
            print("-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Táº¡m biá»‡t!")
            break
        except Exception as e:
            print(f"\nâŒ Lá»—i: {e}\n")