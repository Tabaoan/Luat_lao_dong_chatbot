# ===================== IMPORTS =====================
import os, re, io
from typing import Dict, Any, List
from pathlib import Path

from dotenv import load_dotenv
load_dotenv(override=True)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.documents import Document
from langchain_pinecone import Pinecone 
from pinecone import Pinecone as PineconeClient, PodSpec # ƒê√öNG
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage, AIMessage 
from langchain_community.document_loaders import PyMuPDFLoader

# ===================== ENV =====================
OPENAI__API_KEY = os.getenv("OPENAI__API_KEY")
OPENAI__EMBEDDING_MODEL = os.getenv("OPENAI__EMBEDDING_MODEL")
OPENAI__MODEL_NAME = os.getenv("OPENAI__MODEL_NAME")
OPENAI__TEMPERATURE = os.getenv("OPENAI__TEMPERATURE")

# ‚¨ÖÔ∏è TH√äM BI·∫æN M√îI TR∆Ø·ªúNG PINECONE
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")
EMBEDDING_DIM = 3072 

llm = ChatOpenAI(
    api_key=OPENAI__API_KEY,
    model_name=OPENAI__MODEL_NAME,
    temperature=float(OPENAI__TEMPERATURE) if OPENAI__TEMPERATURE else 0
)

# Kh·ªüi t·∫°o Pinecone Client
if PINECONE_API_KEY:
    pc = PineconeClient(api_key=PINECONE_API_KEY)
else:
    pc = None
    print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y PINECONE_API_KEY. Pinecone s·∫Ω kh√¥ng ho·∫°t ƒë·ªông.")

# ===================== VECTORDB =====================
# VECTORDB_PATH = r"./vectordb_storage" # KH√îNG D√ôNG N·ªÆA
# os.makedirs(VECTORDB_PATH, exist_ok=True) # KH√îNG D√ôNG N·ªÆA

emb = OpenAIEmbeddings(api_key=OPENAI__API_KEY, model=OPENAI__EMBEDDING_MODEL)

vectordb = None
retriever = None

# ===================== PDF FOLDER =====================
PDF_FOLDER = "./data"


def get_pdf_files_from_folder(folder_path: str) -> List[str]:
    """L·∫•y t·∫•t c·∫£ file PDF trong folder"""
    pdf_files = []
    if not os.path.exists(folder_path):
        print(f"‚ö†Ô∏è Folder kh√¥ng t·ªìn t·∫°i: {folder_path}")
        return pdf_files
    
    for file in os.listdir(folder_path):
        if file.lower().endswith('.pdf'):
            full_path = os.path.join(folder_path, file)
            pdf_files.append(full_path)
    
    return sorted(pdf_files) 

PDF_PATHS = get_pdf_files_from_folder(PDF_FOLDER)

# ===================== SYSTEM PROMPT (Gi·ªØ nguy√™n) =====================
PDF_READER_SYS = (
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI ph√°p l√Ω chuy√™n ƒë·ªçc hi·ªÉu v√† tra c·ª©u c√°c t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p "
    "(bao g·ªìm: Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Quy·∫øt ƒë·ªãnh, Th√¥ng t∆∞, VƒÉn b·∫£n h·ª£p nh·∫•t, Quy ho·∫°ch, Danh m·ª•c khu c√¥ng nghi·ªáp, v.v.). "
    "Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t v√† tr·∫£ l·ªùi ch√≠nh x√°c c√°c th√¥ng tin c√≥ trong t√†i li·ªáu, "
    "ƒë·∫∑c bi·ªát li√™n quan ƒë·∫øn Lao ƒë·ªông, D√¢n s·ª± v√† c√°c Khu c√¥ng nghi·ªáp, C·ª•m c√¥ng nghi·ªáp t·∫°i Vi·ªát Nam.\n\n"

    
    "‚öôÔ∏è QUY T·∫ÆC ƒê·∫∂C BI·ªÜT:\n"
    "- N·∫øu ng∆∞·ªùi d√πng ch·ªâ ch√†o h·ªèi ho·∫∑c ƒë·∫∑t c√¢u h·ªèi chung chung (v√≠ d·ª•: 'xin ch√†o', 'b·∫°n l√†m ƒë∆∞·ª£c g√¨', 'gi√∫p t√¥i v·ªõi' ...), "
    "h√£y tr·∫£ l·ªùi nguy√™n vƒÉn nh∆∞ sau:\n"
    "'Xin ch√†o! M√¨nh l√† Chatbot C·ªïng vi·ªác l√†m Vi·ªát Nam. M√¨nh c√≥ th·ªÉ gi√∫p anh/ch·ªã tra c·ª©u v√† gi·∫£i th√≠ch c√°c quy ƒë·ªãnh ph√°p lu·∫≠t "
    "(lu·∫≠t, ngh·ªã ƒë·ªãnh, th√¥ng t∆∞...) li√™n quan ƒë·∫øn lao ƒë·ªông, vi·ªác l√†m, d√¢n s·ª± v√† c√°c lƒ©nh v·ª±c ph√°p l√Ω kh√°c. "
    "G√µ c√¢u h·ªèi c·ª• th·ªÉ ho·∫∑c m√¥ t·∫£ t√¨nh hu·ªëng nh√© ‚Äî m√¨nh s·∫Ω tr·∫£ l·ªùi ng·∫Øn g·ªçn, c√≥ d·∫´n ngu·ªìn.'\n\n"

    "üìò NGUY√äN T·∫ÆC CHUNG KHI TR·∫¢ L·ªúI:\n"
    "1) Ph·∫°m vi: Ch·ªâ d·ª±a v√†o n·ªôi dung trong c√°c t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c cung c·∫•p; tuy·ªát ƒë·ªëi kh√¥ng s·ª≠ d·ª•ng ho·∫∑c suy di·ªÖn ki·∫øn th·ª©c b√™n ngo√†i.\n"
    "2) Ngu·ªìn tr√≠ch d·∫´n: Khi c√≥ th·ªÉ, ch·ªâ ghi r√µ ngu·ªìn theo quy ƒë·ªãnh (v√≠ d·ª•: Theo ƒêi·ªÅu X, Ngh·ªã ƒë·ªãnh s·ªë Y/Nƒê-CP...), "
    "nh∆∞ng kh√¥ng ƒë∆∞·ª£c ghi theo d·∫°ng li·ªát k√™ t√†i li·ªáu nh∆∞ [1], [2], [3]... Kh√¥ng ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng ho·∫∑c nh·∫Øc ƒë·∫øn c·ª•m t·ª´ nh∆∞:'t√†i li·ªáu PDF', 'tr√≠ch t·ª´ t√†i li·ªáu PDF', 'd∆∞·ªõi ƒë√¢y l√† th√¥ng tin t·ª´ t√†i li·ªáu PDF', ho·∫∑c c√°c c·ª•m t∆∞∆°ng t·ª±."
    "Thay v√†o ƒë√≥, ch·ªâ n√™u tr·ª±c ti·∫øp n·ªôi dung ph√°p lu·∫≠t, v√≠ d·ª•: 'Th√¥ng tin li√™n quan ƒë·∫øn Lu·∫≠t Vi·ªác l√†m quy ƒë·ªãnh r·∫±ng...'.\n"
    "3) Ng√¥n ng·ªØ: S·ª≠ d·ª•ng vƒÉn phong ph√°p l√Ω, trung l·∫≠p, r√µ r√†ng v√† t√¥n tr·ªçng ng·ªØ ƒëi·ªáu h√†nh ch√≠nh.\n"
    "4) Tr√¨nh b√†y: ∆Øu ti√™n tr√¨nh b√†y d∆∞·ªõi d·∫°ng danh s√°ch (s·ªë th·ª© t·ª± ho·∫∑c g·∫°ch ƒë·∫ßu d√≤ng) ƒë·ªÉ d·ªÖ theo d√µi; "
    "tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng k√Ω hi·ªáu in ƒë·∫≠m (** ho·∫∑c __) trong b·∫•t k·ª≥ ph·∫ßn tr·∫£ l·ªùi n√†o.\n"
    "5) N·∫øu th√¥ng tin kh√¥ng c√≥: Tr·∫£ l·ªùi r√µ r√†ng: 'Th√¥ng tin n√†y kh√¥ng c√≥ trong t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p.'\n"
    "6) N·∫øu c√¢u h·ªèi m∆° h·ªì: Y√™u c·∫ßu ng∆∞·ªùi d√πng l√†m r√µ ho·∫∑c b·ªï sung chi ti·∫øt ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c h∆°n.\n"
    
    "Kh√¥ng ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng ho·∫∑c nh·∫Øc ƒë·∫øn c·ª•m t·ª´ nh∆∞: " "'t√†i li·ªáu PDF', 'tr√≠ch t·ª´ t√†i li·ªáu PDF', 'd∆∞·ªõi ƒë√¢y l√† th√¥ng tin t·ª´ t√†i li·ªáu PDF', ho·∫∑c c√°c c·ª•m t∆∞∆°ng t·ª±. " 
    "Thay v√†o ƒë√≥, ch·ªâ n√™u tr·ª±c ti·∫øp n·ªôi dung ph√°p lu·∫≠t, v√≠ d·ª•: 'Th√¥ng tin li√™n quan ƒë·∫øn Lu·∫≠t Vi·ªác l√†m quy ƒë·ªãnh r·∫±ng...'.\n"

    "üè≠ QUY ƒê·ªäNH RI√äNG ƒê·ªêI V·ªöI C√ÅC KHU C√îNG NGHI·ªÜP / C·ª§M C√îNG NGHI·ªÜP:\n"
    "1) N·∫øu ng∆∞·ªùi d√πng h·ªèi 'T·ªânh/th√†nh ph·ªë n√†o c√≥ bao nhi√™u khu ho·∫∑c c·ª•m c√¥ng nghi·ªáp', "
    "h√£y tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng sau:\n"
    "   - S·ªë l∆∞·ª£ng khu/c·ª•m c√¥ng nghi·ªáp trong t·ªânh ho·∫∑c th√†nh ph·ªë ƒë√≥.\n"
    "   - Danh s√°ch t√™n c·ªßa t·∫•t c·∫£ c√°c khu/c·ª•m.\n\n"
    "   V√≠ d·ª•:\n"
    "   'T·ªânh B√¨nh D∆∞∆°ng c√≥ 29 khu c√¥ng nghi·ªáp. Bao g·ªìm:\n"
    "   - Khu c√¥ng nghi·ªáp S√≥ng Th·∫ßn 1\n"
    "   - Khu c√¥ng nghi·ªáp VSIP 1\n"
    "   - Khu c√¥ng nghi·ªáp M·ªπ Ph∆∞·ªõc 3\n"
    "   ...'\n\n"

    "2) N·∫øu ng∆∞·ªùi d√πng h·ªèi chi ti·∫øt v·ªÅ m·ªôt khu/c·ª•m c√¥ng nghi·ªáp c·ª• th·ªÉ (l·∫ßn ƒë·∫ßu ti√™n), h√£y tr√¨nh b√†y ƒë·∫ßy ƒë·ªß th√¥ng tin (n·∫øu c√≥ trong t√†i li·ªáu), g·ªìm:\n"
    "   - T√™n khu c√¥ng nghi·ªáp / c·ª•m c√¥ng nghi·ªáp\n"
    "   - ƒê·ªãa ƒëi·ªÉm (t·ªânh/th√†nh ph·ªë, huy·ªán/th·ªã x√£)\n"
    "   - Di·ªán t√≠ch (ha ho·∫∑c m¬≤)\n"
    "   - C∆° quan qu·∫£n l√Ω / ch·ªß ƒë·∫ßu t∆∞\n"
    "   - Quy·∫øt ƒë·ªãnh th√†nh l·∫≠p ho·∫∑c ph√™ duy·ªát quy ho·∫°ch\n"
    "   - Ng√†nh ngh·ªÅ ho·∫°t ƒë·ªông ch√≠nh\n"
    "   - T√¨nh tr·∫°ng ho·∫°t ƒë·ªông (ƒëang ho·∫°t ƒë·ªông / ƒëang quy ho·∫°ch / ƒëang x√¢y d·ª±ng)\n"
    "   - C√°c th√¥ng tin kh√°c li√™n quan (n·∫øu c√≥)\n\n"

    "3) N·∫øu ng∆∞·ªùi d√πng ti·∫øp t·ª•c h·ªèi chi ti·∫øt v·ªÅ c√°c c·ª•m ho·∫∑c khu c√¥ng nghi·ªáp (t·ª´ l·∫ßn th·ª© hai tr·ªü ƒëi), "
    "h√£y kh√¥ng li·ªát k√™ l·∫°i th√¥ng tin chi ti·∫øt, m√† tr·∫£ l·ªùi c·ªë ƒë·ªãnh nh∆∞ sau:\n"
    "'N·∫øu b·∫°n mu·ªën bi·∫øt th√™m th√¥ng tin chi ti·∫øt v·ªÅ c√°c c·ª•m, h√£y truy c·∫≠p v√†o website https://iipmap.com/.'\n\n"

    "4) N·∫øu ng∆∞·ªùi d√πng ch·ªâ h·ªèi th·ªëng k√™ (v√≠ d·ª•: 'T·ªânh B·∫Øc Ninh c√≥ bao nhi√™u c·ª•m c√¥ng nghi·ªáp?'), "
    "h√£y lu√¥n tr·∫£ l·ªùi s·ªë l∆∞·ª£ng v√† li·ªát k√™ t√™n c·ª•m/khu theo quy ƒë·ªãnh t·∫°i m·ª•c (1) ·ªü tr√™n.\n\n"

    "5) N·∫øu ng∆∞·ªùi d√πng h·ªèi c√¢u ngo√†i ph·∫°m vi ph√°p lu·∫≠t ho·∫∑c khu/c·ª•m c√¥ng nghi·ªáp "
    "(v√≠ d·ª•: h·ªèi v·ªÅ tuy·ªÉn d·ª•ng, gi√° ƒë·∫•t, ƒë·∫ßu t∆∞ c√° nh√¢n, v.v.), "
    "h√£y tr·∫£ l·ªùi nguy√™n vƒÉn nh∆∞ sau:\n"
    "'Anh/ch·ªã vui l√≤ng ƒë·ªÉ l·∫°i t√™n v√† s·ªë ƒëi·ªán tho·∫°i, chuy√™n gia c·ªßa IIP s·∫Ω li√™n h·ªá v√† gi·∫£i ƒë√°p c√°c y√™u c·∫ßu c·ªßa anh/ch·ªã ·∫°.'\n\n"
)

# ===================== VECTORDB UTILS (C·∫≠p nh·∫≠t cho Pinecone) =====================
def build_context_from_hits(hits, max_chars: int = 6000) -> str:
    """X√¢y d·ª±ng context t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm"""
    ctx = []
    total = 0
    for idx, h in enumerate(hits, start=1):
        # Pinecone retriever tr·∫£ v·ªÅ Document
        source = h.metadata.get('source', 'unknown')
        page = h.metadata.get('page', '?')
        seg = f"[{idx}] (Ngu·ªìn: {source}, Trang: {page})\n{h.page_content.strip()}"
        if total + len(seg) > max_chars:
            break
        ctx.append(seg)
        total += len(seg)
    return "\n\n".join(ctx)

def get_existing_sources() -> set:
    """L·∫•y danh s√°ch file ƒë√£ c√≥ trong VectorDB (Pinecone - Gi·∫£ l·∫≠p v√¨ API kh√¥ng h·ªó tr·ª£ d·ªÖ d√†ng)"""
    # Trong m√¥i tr∆∞·ªùng Pinecone, vi·ªác l·∫•y t·∫•t c·∫£ sources t·ª´ metadata kh√¥ng hi·ªáu qu·∫£.
    # Ta s·∫Ω tr·∫£ v·ªÅ r·ªóng v√† d·ª±a v√†o force_reload/ki·ªÉm tra vector count.
    return set()

def check_vectordb_exists() -> bool:
    """Ki·ªÉm tra xem Pinecone Index c√≥ t·ªìn t·∫°i v√† c√≥ vectors kh√¥ng"""
    global pc, vectordb, retriever
    
    if pc is None or not PINECONE_INDEX_NAME:
        return False

    try:
        # Ki·ªÉm tra index c√≥ t·ªìn t·∫°i kh√¥ng
        # S·ª¨A L·ªñI ƒê√É ƒê∆Ø·ª¢C TH·ª∞C HI·ªÜN ·ªû ƒê√ÇY (ƒê√É C√ì ())
        if PINECONE_INDEX_NAME not in pc.list_indexes().names(): 
            return False
            
        # L·∫•y th·ªëng k√™
        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()
        total_vectors = stats['total_vector_count']
        
        if total_vectors > 0:
            # N·∫øu ƒë√£ c√≥ vectors, kh·ªüi t·∫°o vectordb v√† retriever (n·∫øu ch∆∞a)
            if vectordb is None:
                 vectordb = Pinecone(
                    index=index, 
                    embedding=emb, 
                    text_key="text"
                )
                 retriever = vectordb.as_retriever(search_kwargs={"k": 50})

            return True
            
        return False
        
    except Exception as e:
        # print(f"‚ö†Ô∏è L·ªói khi ki·ªÉm tra Pinecone Index: {e}")
        return False

def get_vectordb_stats() -> Dict[str, Any]:
    """L·∫•y th√¥ng tin th·ªëng k√™ v·ªÅ VectorDB (Pinecone)"""
    global pc
    
    # S·ª¨A L·ªñI ƒê√É ƒê∆Ø·ª¢C TH·ª∞C HI·ªÜN ·ªû ƒê√ÇY (ƒê√É C√ì ())
    if pc is None or not PINECONE_INDEX_NAME or PINECONE_INDEX_NAME not in pc.list_indexes().names():
        return {"total_documents": 0, "name": PINECONE_INDEX_NAME, "exists": False, "sources": []}
    
    try:
        index = pc.Index(PINECONE_INDEX_NAME)
        stats = index.describe_index_stats()
        
        count = stats['total_vector_count']
        sources = ["Th√¥ng tin ngu·ªìn c·∫ßn n·∫°p l·∫°i ƒë·ªÉ c·∫≠p nh·∫≠t."]
        
        return {
            "total_documents": count,
            "name": PINECONE_INDEX_NAME,
            "exists": count > 0,
            "sources": sources,
            "dimension": stats.get('dimension', EMBEDDING_DIM)
        }
    except Exception as e:
        return {
            "total_documents": 0,
            "name": PINECONE_INDEX_NAME,
            "exists": False,
            "error": str(e),
            "sources": []
        }

# ===================== INGEST MULTIPLE PDFs (Pinecone) =====================
def ingest_pdf(pdf_paths=None, emb_fn=None, force_reload=False):
    """
    N·∫°p t√†i li·ªáu PDF v√†o VectorDB (Pinecone)
    """
    global vectordb, retriever, pc

    if pc is None:
        print("‚ùå L·ªói: Pinecone Client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Vui l√≤ng ki·ªÉm tra PINECONE_API_KEY.")
        return None
    
    pdf_paths = pdf_paths if pdf_paths is not None else PDF_PATHS
    emb_fn = emb_fn if emb_fn is not None else emb

    print("üöÄ B·∫Øt ƒë·∫ßu ki·ªÉm tra v√† n·∫°p t√†i li·ªáu PDF v√†o Pinecone...\n")
    
    index_name = PINECONE_INDEX_NAME
    
    # 1. X·ª≠ l√Ω Force Reload: X√≥a Index v√† t·∫°o l·∫°i
    if force_reload:
        print(f"üóëÔ∏è Ch·∫ø ƒë·ªô force reload - X√≥a Index '{index_name}'...")
        # S·ª¨A L·ªñI ƒê√É ƒê∆Ø·ª¢C TH·ª∞C HI·ªÜN ·ªû ƒê√ÇY (ƒê√É C√ì ())
        if index_name in pc.list_indexes().names():
            pc.delete_index(index_name)
            print(f"‚úÖ ƒê√£ x√≥a Index '{index_name}'\n")
        else:
             print(f"‚ÑπÔ∏è Index '{index_name}' kh√¥ng t·ªìn t·∫°i. Ti·∫øp t·ª•c t·∫°o m·ªõi.")
        vectordb = None
        retriever = None

    # 2. T·∫°o Index n·∫øu ch∆∞a t·ªìn t·∫°i
    # S·ª¨A L·ªñI ƒê√É ƒê∆Ø·ª¢C TH·ª∞C HI·ªÜN ·ªû ƒê√ÇY (ƒê√É C√ì ())
    if index_name not in pc.list_indexes().names():
        print(f"üõ†Ô∏è Index '{index_name}' ch∆∞a t·ªìn t·∫°i. ƒêang t·∫°o Index m·ªõi...")
        
        if PINECONE_ENVIRONMENT:
             pc.create_index(
                name=index_name,
                dimension=EMBEDDING_DIM,
                metric='cosine',
                spec=PodSpec(environment=PINECONE_ENVIRONMENT)
             )
        else:
             print("‚ùå L·ªói: PINECONE_ENVIRONMENT ch∆∞a ƒë∆∞·ª£c khai b√°o. Kh√¥ng th·ªÉ t·∫°o Index.")
             return None

        print(f"‚úÖ ƒê√£ t·∫°o Index '{index_name}'.")

    # 3. K·∫øt n·ªëi ƒë·∫øn Index
    index = pc.Index(index_name)
    stats = index.describe_index_stats()
    existing_vectors = stats['total_vector_count']
    
    print(f"üìä Pinecone Index '{index_name}' hi·ªán c√≥: {existing_vectors} vectors.")
    
    # 4. Logic n·∫°p: Ch·ªâ n·∫°p n·∫øu force_reload=True HO·∫∂C index ch∆∞a c√≥ vectors
    if existing_vectors > 0 and not force_reload:
        print("\n‚úÖ Index ƒë√£ c√≥ d·ªØ li·ªáu. Kh√¥ng n·∫°p l·∫°i.")
        vectordb = Pinecone(index=index, embedding=emb_fn, text_key="text")
        retriever = vectordb.as_retriever(search_kwargs={"k": 50})
        return vectordb
    
    # Chu·∫©n b·ªã n·∫°p document
    print("\nüì• B·∫Øt ƒë·∫ßu ƒë·ªçc v√† chunk documents ƒë·ªÉ n·∫°p...")
    all_new_docs = []
    total_chunks = 0
    
    # ƒê·ªçc v√† chunk t·∫•t c·∫£ file PDF
    for filename, path in {os.path.basename(p): p for p in pdf_paths}.items():
        if not os.path.exists(path):
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file: {path}")
            continue

        print(f"üìñ ƒêang ƒë·ªçc: {filename} ...")

        loader = PyMuPDFLoader(path)
        try:
            docs = loader.load()
        except Exception as e:
            print(f"‚ùå L·ªói khi load {filename}: {e}")
            continue

        # G·∫Øn th√¥ng tin ngu·ªìn file
        for i, d in enumerate(docs):
            if d.metadata is None: d.metadata = {}
            d.metadata["source"] = filename
            d.metadata["page"] = i + 1

        # Chunk n·ªôi dung
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=300,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        split_docs = splitter.split_documents(docs)

        # G·∫Øn th√™m chunk index
        for i, d in enumerate(split_docs):
            d.metadata["chunk_id"] = i
            
        print(f" ¬† üîπ T·∫°o {len(split_docs)} ƒëo·∫°n t·ª´ {filename}")
        all_new_docs.extend(split_docs)
        total_chunks += len(split_docs)
        
    if not all_new_docs:
        print("‚ö†Ô∏è Kh√¥ng c√≥ document n√†o ƒë·ªÉ n·∫°p.")
        return None
    
    print(f"\nüìö T·ªïng c·ªông: {total_chunks} ƒëo·∫°n n·ªôi dung m·ªõi\n")

    # Th√™m v√†o Pinecone
    print("üíæ ƒêang n·∫°p documents v√†o Pinecone Index...")
    
    try:
        # S·ª≠ d·ª•ng Pinecone.from_documents ƒë·ªÉ n·∫°p
        # H√†m n√†y s·∫Ω t·ª± ƒë·ªông t·∫°o embedding v√† g·ª≠i batch l√™n Pinecone
        vectordb = Pinecone.from_documents(
            all_new_docs,
            index_name=index_name,
            embedding=emb_fn,
            text_key="text" 
        )
        print("‚úÖ ƒê√£ n·∫°p to√†n b·ªô documents m·ªõi v√†o Pinecone!")
    except Exception as e:
        print(f"‚ùå L·ªói khi th√™m documents v√†o Pinecone: {e}")
        return None

    # C·∫≠p nh·∫≠t retriever
    retriever = vectordb.as_retriever(search_kwargs={"k": 50})

    # Th·ªëng k√™ cu·ªëi c√πng
    stats = get_vectordb_stats()
    print(f"\nüìä Pinecone Index hi·ªán c√≥:")
    print(f" ¬† ‚Ä¢ T·ªïng documents: {stats['total_documents']}")
    print(f" ¬† ‚Ä¢ T√™n Index: {stats['name']}\n")
    
    return vectordb

# ===================== CLEANING & RETRIEVAL (Gi·ªØ nguy√™n) =====================
_URL_RE = re.compile(r"https?://[^\s]+", re.IGNORECASE)
FIXED_RESPONSE_Q3 = 'N·∫øu b·∫°n mu·ªën bi·∫øt th√™m th√¥ng tin chi ti·∫øt v·ªÅ c√°c c·ª•m, h√£y truy c·∫≠p v√†o website https://iipmap.com/.'

def clean_question_remove_uris(text: str) -> str:
    """L√†m s·∫°ch c√¢u h·ªèi, lo·∫°i b·ªè URL v√† t√™n file PDF"""
    txt = _URL_RE.sub(" ", text or "")
    toks = re.split(r"\s+", txt)
    toks = [t for t in toks if not t.lower().endswith(".pdf")]
    return " ".join(toks).strip()

def is_detail_query(text: str) -> bool:
    """Ki·ªÉm tra xem c√¢u h·ªèi c√≥ ph·∫£i l√† c√¢u h·ªèi chi ti·∫øt v·ªÅ khu/c·ª•m c√¥ng nghi·ªáp hay kh√¥ng"""
    text_lower = text.lower()
    keywords = ["n√™u chi ti·∫øt", "chi ti·∫øt v·ªÅ", "th√¥ng tin chi ti·∫øt", "c·ª•m c√¥ng nghi·ªáp", "khu c√¥ng nghi·ªáp"]
    if any(k in text_lower for k in keywords):
        if "c√≥ bao nhi√™u" in text_lower or "th·ªëng k√™" in text_lower:
            return False
        return True
    return False

def count_previous_detail_queries(history: List[BaseMessage]) -> int:
    """ƒê·∫øm s·ªë l·∫ßn h·ªèi chi ti·∫øt v·ªÅ KCN/CCN ƒë√£ ƒë∆∞·ª£c tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥ (l·∫ßn ƒë·∫ßu ƒë∆∞·ª£c t√≠nh l√† 0)"""
    count = 0
    for i in range(len(history)):
        current_message = history[i]
        if isinstance(current_message, HumanMessage):
            is_q = is_detail_query(current_message.content)
            
            if is_q and i + 1 < len(history) and isinstance(history[i+1], AIMessage):
                bot_response = history[i+1].content
                if FIXED_RESPONSE_Q3 not in bot_response:
                    count += 1
    return count

def process_pdf_question(i: Dict[str, Any]) -> str:
    """X·ª≠ l√Ω c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng"""
    global retriever
    
    message = i["message"]
    history: List[BaseMessage] = i.get("history", [])

    clean_question = clean_question_remove_uris(message)
    
    if is_detail_query(clean_question):
        count_detail_queries = count_previous_detail_queries(history)

        if count_detail_queries >= 1: 
            return FIXED_RESPONSE_Q3
    
    # Ki·ªÉm tra VectorDB v√† t·ª± ƒë·ªông n·∫°p n·∫øu c·∫ßn (Ch·ªâ ch·∫°y khi Index tr·ªëng)
    if not check_vectordb_exists():
        print("‚ö†Ô∏è VectorDB (Pinecone) ch∆∞a s·∫µn s√†ng ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu, ƒëang n·∫°p PDF...")
        result = ingest_pdf()
        if result is None:
             return "Xin l·ªói, t√¥i g·∫∑p l·ªói khi n·∫°p t√†i li·ªáu PDF v√†o Pinecone. Vui l√≤ng ki·ªÉm tra API Key v√† Index Name."

    try:
        # T√¨m ki·∫øm trong VectorDB
        hits = retriever.invoke(clean_question)
        
        if not hits:
            return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu."

        # X√¢y d·ª±ng context t·ª´ k·∫øt qu·∫£ t√¨m ki·∫øm
        context = build_context_from_hits(hits, max_chars=6000)
        
        # T·∫°o messages
        messages = [SystemMessage(content=PDF_READER_SYS)]
        if history:
            messages.extend(history[-10:]) 

        user_message = f"""C√¢u h·ªèi: {clean_question}

N·ªôi dung li√™n quan t·ª´ t√†i li·ªáu:
{context}

H√£y tr·∫£ l·ªùi d·ª±a tr√™n c√°c n·ªôi dung tr√™n."""
        
        messages.append(HumanMessage(content=user_message))
        
        # G·ªçi LLM
        response = llm.invoke(messages).content
        
        return response

    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"

# ===================== MAIN CHATBOT (Gi·ªØ nguy√™n) =====================
pdf_chain = RunnableLambda(process_pdf_question)
store: Dict[str, ChatMessageHistory] = {}

def get_history(session_id: str):
    """L·∫•y ho·∫∑c t·∫°o l·ªãch s·ª≠ chat cho session"""
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

chatbot = RunnableWithMessageHistory(
    pdf_chain,
    get_history,
    input_messages_key="message",
    history_messages_key="history"
)

def print_help():
    """In h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"""
    print("\n" + "="*60)
    print("üìö C√ÅC L·ªÜNH C√ì S·∫¥N:")
    print("="*60)
    print(" - exit / quit ¬†: Tho√°t ch∆∞∆°ng tr√¨nh")
    print(" - clear ¬† ¬† ¬† ¬†: X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i")
    print(" - sync / reload: X√≥a v√† N·∫†P L·∫†I to√†n b·ªô PDF v√†o Pinecone Index") 
    print(" - status ¬† ¬† ¬† : Ki·ªÉm tra tr·∫°ng th√°i Pinecone Index")
    print(" - help ¬† ¬† ¬† ¬† : Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n n√†y")
    print("="*60 + "\n")

def handle_command(command: str, session: str) -> bool:
    """X·ª≠ l√Ω c√°c l·ªánh ƒë·∫∑c bi·ªát"""
    global vectordb, retriever
    cmd = command.lower().strip()

    if cmd in {"exit", "quit"}:
        print("\nüëã T·∫°m bi·ªát! H·∫πn g·∫∑p l·∫°i!")
        return False
    
    elif cmd == "clear":
        if session in store:
            store[session].clear()
            print("üßπ ƒê√£ x√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i.\n")
        return True
    
    elif cmd in {"reload", "sync"}:
        print("üîÑ ƒêang x√≥a v√† n·∫°p l·∫°i to√†n b·ªô PDF v√†o Pinecone Index...")
        ingest_pdf(force_reload=True)
        return True
    
    elif cmd == "status":
        stats = get_vectordb_stats()
        print("\n" + "="*60)
        print("üìä TR·∫†NG TH√ÅI VECTORDB (PINECONE)")
        print("="*60)
        if stats["exists"]:
            print(f"‚úÖ Tr·∫°ng th√°i: S·∫µn s√†ng")
            print(f"üìö T√™n Index: {stats['name']}")
            print(f"üìä T·ªïng documents: {stats['total_documents']}")
            print(f"üìè Dimension: {stats['dimension']}")
        else:
            print("‚ùå Tr·∫°ng th√°i: Ch∆∞a s·∫µn s√†ng")
            print(f"üí° Index '{PINECONE_INDEX_NAME}' kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng c√≥ documents.")
        print("="*60 + "\n")
        return True
    
    elif cmd == "help":
        print_help()
        return True
    
    else:
        return True

# ===================== CLI =====================
if __name__ == "__main__":
    session = "pdf_reader_session"

    # KI·ªÇM TRA M√îI TR∆Ø·ªúNG PINECONE
    if not all([PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME]):
        print("‚ùå L·ªñI: Thi·∫øu m·ªôt ho·∫∑c nhi·ªÅu bi·∫øn m√¥i tr∆∞·ªùng Pinecone (PINECONE_API_KEY, PINECONE_ENVIRONMENT, PINECONE_INDEX_NAME).")
        exit(1)


    print("\n" + "="*60)
    print("ü§ñ CHATBOT C·ªîNG VI·ªÜC L√ÄM VI·ªÜT NAM (D√ôNG PINECONE)")
    print("="*60)
    print(f"üìÅ Folder t√†i li·ªáu: {PDF_FOLDER}")
    print(f"üìö T√¨m th·∫•y {len(PDF_PATHS)} file PDF.")
    
    if PDF_PATHS:
        for idx, p in enumerate(PDF_PATHS, 1):
            status = "‚úÖ" if os.path.exists(p) else "‚ùå"
            print(f" ¬† {idx}. {status} {os.path.basename(p)}")
    else:
        print(" ¬† ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file PDF n√†o trong folder!")
    
    print(f"\n‚òÅÔ∏è Pinecone Index: {PINECONE_INDEX_NAME}")
    print("üîç T√¥i h·ªó tr·ª£: Lu·∫≠t Lao ƒë·ªông & Lu·∫≠t D√¢n s·ª± Vi·ªát Nam")
    print_help()

    # Kh·ªüi t·∫°o VectorDB (K·∫øt n·ªëi ho·∫∑c t·∫°o Index)
    if not PDF_PATHS:
        print("‚ùå Kh√¥ng c√≥ file PDF n√†o ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra l·∫°i folder.")
        exit(1)
    
    if check_vectordb_exists():
        stats = get_vectordb_stats()
        print(f"‚úÖ Pinecone s·∫µn s√†ng: Index '{stats['name']}' v·ªõi {stats['total_documents']} documents.")
    else:
        print("üì• ƒêang n·∫°p PDF l·∫ßn ƒë·∫ßu ti√™n v√†o Pinecone Index...")
        result = ingest_pdf()
        if result is None:
            print("‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o Index. Vui l√≤ng ki·ªÉm tra Pinecone API Key v√† m√¥i tr∆∞·ªùng.")
            exit(1)

    print("üí¨ S·∫µn s√†ng tr·∫£ l·ªùi c√¢u h·ªèi! (G√µ 'help' ƒë·ªÉ xem h∆∞·ªõng d·∫´n)\n")

    # Main loop
    while True:
        try:
            message = input("üë§ B·∫°n: ").strip()
            
            if not message:
                continue
            
            # X·ª≠ l√Ω l·ªánh
            if not handle_command(message, session):
                break
            
            # B·ªè qua n·∫øu l√† l·ªánh
            if message.lower() in ["clear", "reload", "sync", "status", "help"]:
                continue
            
            # X·ª≠ l√Ω c√¢u h·ªèi th∆∞·ªùng
            print("üîé ƒêang t√¨m ki·∫øm trong Index Pinecone...")
            response = chatbot.invoke(
                {"message": message},
                config={"configurable": {"session_id": session}}
            )
            print(f"\nü§ñ Bot: {response}\n")
            print("-" * 60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nüëã T·∫°m bi·ªát!")
            break
        except Exception as e:
            print(f"\n‚ùå L·ªói: {e}\n")